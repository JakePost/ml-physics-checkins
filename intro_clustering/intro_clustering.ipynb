{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple notebook that gives a demonstration of k-means, DBSCAN and GMM.\n",
    "\n",
    "It accompanies Chapter 7 of the book (1 of 4) and shows how different figures were made.\n",
    "\n",
    "A little less polished than others as a lecture notebook.\n",
    "\n",
    "Author: Viviana Acquaviva, with contributions by Jake Postiglione and Olga Privman; see also other sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = make_blobs(n_samples=300, centers=4,\n",
    "                       cluster_std=0.6, random_state=2)\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "start = np.array([[-1,1],[1,-1],[3,-3],[-5,-10]]) #initial points (fixed for reproducibility)\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.scatter(X[:, 0], X[:, 1], s =3, c ='gray') # plot original points\n",
    "plt.scatter(start[:,0],start[:,1], s = 20, c = 'k', label = 'Iteration 0');\n",
    "plt.xlim(-10,5);\n",
    "plt.annotate('Iteration 0', xy=(77, 20), xycoords='axes points',\n",
    "            size=14, ha='right', va='top')\n",
    "#plt.legend(loc='lower left');\n",
    "\n",
    "for i in range(1,4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    kmeans = KMeans(n_clusters=4, max_iter = i, init = start, n_init=1)\n",
    "    kmeans.fit(X)\n",
    "    y_kmeans = kmeans.predict(X)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    plt.scatter(X[:, 0], X[:, 1], s = 3, c = y_kmeans, cmap = 'rainbow') # plot original points\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], s=20, \\\n",
    "                edgecolor = 'k', label = 'Iteration'+str(i), c = [0,1,2,3],cmap = 'rainbow');\n",
    "    plt.xlim(-10,5);\n",
    "#    plt.legend(loc='lower left', numpoints=1);\n",
    "    plt.annotate('Iteration '+str(i), xy=(77, 20), xycoords='axes points',\n",
    "            size=14, ha='right', va='top')\n",
    "#            bbox=dict(boxstyle='round', fc='w'))\n",
    "#plt.savefig('Clustering_iterations.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Check-in\n",
    "    \n",
    "Q: Based on the top left graph labled \"Iteration 0\" how many groups of dots would you say there are?\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">Answer</summary>\n",
    "<p>\n",
    "There are 4 groups of dots or \"clusters\". This may have been an easy proccess for a human, but how do we effectively have a computer due this for us. Check out the examples below detailing some more difficult situations we can run into with clustering.\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First slightly tricky example: overlapping blobs of different size/density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1b, y1b = make_blobs(n_samples=200, centers=[(1.25,1)],\n",
    "                       cluster_std=0.2, random_state=1)\n",
    "\n",
    "X2b, y2b = make_blobs(n_samples=400, centers=[(0,1)],\n",
    "                       cluster_std=0.5, random_state=2)\n",
    "\n",
    "X3b, y3b = make_blobs(n_samples=200, centers=[(-1.25,1)],\n",
    "                       cluster_std=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.scatter(X1b[:, 0], X1b[:, 1], s =10, c ='gray') # plot original points\n",
    "\n",
    "plt.scatter(X2b[:, 0], X2b[:, 1], s =10, c ='violet') # plot original points\n",
    "\n",
    "plt.scatter(X3b[:, 0], X3b[:, 1], s =10, c ='teal') # plot original points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb = np.vstack([X1b,X2b,X3b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=33) #predicts 0,1,2\n",
    "kmeans.fit(Xb)\n",
    "yb_kmeans = kmeans.predict(Xb)\n",
    "centersb = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = np.concatenate([np.zeros(len(y1b)),np.zeros(len(y2b))+1,np.zeros(len(y3b))+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "model = KMeans(n_clusters=3, random_state=33) #predicts 0,1,2\n",
    "model.fit(Xb)\n",
    "plot_decision_regions(Xb, yb.astype(int), clf=model, legend=0, markers = '...', colors = 'lightgray,violet,teal')\n",
    "plt.scatter(X1b[:,0],X1b[:,1], s = 30, c = 'lightgray',edgecolors='k')\n",
    "plt.scatter(X2b[:,0],X2b[:,1], s = 30, c = 'teal', edgecolors='k')\n",
    "plt.scatter(X3b[:,0],X3b[:,1],s = 30, c = 'violet', edgecolors='k')\n",
    "plt.scatter(centersb[:, 0], centersb[:, 1], c='black', s=100, alpha=0.5);\n",
    "\n",
    "plt.xlim(-2.5,2.5)\n",
    "plt.ylim(-0.5,2.5);\n",
    "\n",
    "#plt.savefig('ClustersBad.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we move on to a different distribution (smiley face)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi, cos, sin\n",
    "from random import random\n",
    "\n",
    "def point(h, k, r):\n",
    "    theta = random() * 2 * pi\n",
    "    return h + cos(theta) * r, k + sin(theta) * r + 0.2*random()\n",
    "\n",
    "xy = [point(1,2,1) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = make_blobs(n_samples=10, centers=[(0.5,2.5)],\n",
    "                       cluster_std=0.05, random_state=1)\n",
    "\n",
    "X2, y2 = make_blobs(n_samples=10, centers=[(1.5,2.5)],\n",
    "                       cluster_std=0.05, random_state=2)\n",
    "\n",
    "X3, y3 = make_blobs(n_samples=10, centers=[(1,1.7)],\n",
    "                       cluster_std=0.05, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_stretch = np.array([X3[:,0]*3, X3[:,1]]) #make the mouth :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "plt.scatter(*zip(*xy))\n",
    "plt.scatter(X1[:,0],X1[:,1])\n",
    "plt.scatter(X2[:,0],X2[:,1])\n",
    "plt.scatter(X3_stretch.T[:,0]-1.9,X3_stretch.T[:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([xy,X1,X2,np.array([X3_stretch.T[:,0]-1.9,X3_stretch.T[:,1]]).T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how k-means clusters these points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4) #We can also change the number of clusters\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "print(centers)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=10, cmap='viridis')\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=100, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([np.zeros(len(xy)), np.zeros(len(y1))+1,np.zeros(len(y2))+2,np.zeros(len(y3))+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plot_decision_regions(X, y.astype(int), clf=kmeans, legend=0, markers = '.', colors = 'lightgray,teal,yellow,violet')\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=100, alpha=0.5);\n",
    "plt.scatter(*zip(*xy), s = 30, c = 'lightgray', edgecolors='k')\n",
    "plt.scatter(X1[:,0],X1[:,1], s = 30, c = 'teal',edgecolors='k')\n",
    "plt.scatter(X2[:,0],X2[:,1], s = 30, c = 'yellow', edgecolors='k')\n",
    "plt.scatter(X3_stretch.T[:,0]-1.9,X3_stretch.T[:,1],s = 30, c = 'violet', edgecolors='k')\n",
    "plt.xlim(-0.5,2.5);\n",
    "plt.ylim(0.5,3.5);\n",
    "#plt.savefig('ClustersBad2.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Check-in\n",
    "    \n",
    "Q: Does this fit look good? Why might out clustering method be preforming like this?\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">Answer</summary>\n",
    "<p>\n",
    "This is not a very good fit! The smiley face is a really tricky example, for several reasons! One of these reasons is the ring surrounding three smaller clusters. When our algorithm fits for the number of clusters, it has a hard time distigusing exactly how the ring contributes to any given cluster.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Elbow curve can be used to infer the number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for the smiley face..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(2, 10), inertias)\n",
    "#plt.grid(True)\n",
    "plt.title('Elbow curve for smiley face');\n",
    "plt.xlabel('Number of clusters $k$', fontsize = 14);\n",
    "plt.ylabel('$k$-means cost function', fontsize = 14);\n",
    "#plt.savefig('ElbowSmiley.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and this is for the blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertiasb = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(Xb)\n",
    "    inertiasb.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(2, 10), inertiasb)\n",
    "#plt.grid(True)\n",
    "plt.title('Elbow curve for blobs');\n",
    "plt.xlabel('Number of clusters $k$', fontsize = 14);\n",
    "plt.ylabel('$k$-means cost function', fontsize = 14);\n",
    "plt.savefig('ElbowBlobs.png', dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smiley face\n",
    "\n",
    "n_clusters = [2,3,4,6]\n",
    "\n",
    "for n in n_clusters:\n",
    "    \n",
    "    model = KMeans(n_clusters = n)\n",
    "\n",
    "    model.fit(X)\n",
    "\n",
    "    y_kmeans = model.predict(X)\n",
    "\n",
    "    silhouette_scores = silhouette_samples(X, y_kmeans)\n",
    "\n",
    "    xlower = 10\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    ax = axs[1]\n",
    "    colors = plt.cm.Accent(y_kmeans.astype(float)/n)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=colors, s=40, cmap='flare', edgecolor='k');\n",
    "    ax.tick_params(axis='both', which='both', labelsize=20);\n",
    "\n",
    "    ax = axs[0]\n",
    "\n",
    "    for i in np.unique(y_kmeans):\n",
    "        ind = y_kmeans==i\n",
    "        silh = np.sort(silhouette_scores[ind])\n",
    "        size_cluster_i = silh.shape[0]\n",
    "        xupper = xlower + size_cluster_i\n",
    "        color = plt.cm.Accent(float(i)/model.n_clusters)\n",
    "        ax.fill_between(np.arange(xlower, xupper), 0, silh, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ax.axhline(y=0, c='k', lw=2)\n",
    "        ax.text(0.05, 0.95, '%0.0f clusters'%n, transform=ax.transAxes, fontsize=20)\n",
    "        ax.text(0.45, 0.95, 'Mean S. score: %0.2f'%np.mean(silhouette_scores), transform=ax.transAxes, fontsize=20)\n",
    "        xlower = xupper + 10\n",
    "        ax.set_ylabel('Silhouette score', fontsize=16)\n",
    "        ax.set_ylim(-0.2,0.8)\n",
    "        \n",
    "    ax.axhline(y=np.mean(silhouette_scores), color=\"red\", linestyle=\"--\")\n",
    "    ax.tick_params(axis='both', which='both', labelsize=20);\n",
    "    ax.set_xticks([]);\n",
    "#    figname = 'SilhouetteSmiley'+str(n)+'.png'\n",
    "#    plt.savefig(figname, dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Check-in\n",
    "    \n",
    "Q: A mean silhouette score closer to 1 means there is littler overlap between the clusters. With that in mind, what is the best Mean S. Score we see above?\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">Answer</summary>\n",
    "<p>\n",
    "The best score we see is a 0.50\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blobs \n",
    "\n",
    "n_clusters = np.arange(2, 6)\n",
    "\n",
    "for n in n_clusters:\n",
    "    \n",
    "    model = KMeans(n_clusters = n)\n",
    "\n",
    "    model.fit(Xb)\n",
    "\n",
    "    y_kmeans = model.predict(Xb)\n",
    "    \n",
    "    silhouette_scores = silhouette_samples(Xb, y_kmeans)\n",
    "\n",
    "    xlower = 10\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    ax = axs[1]\n",
    "    colors = plt.cm.Accent(y_kmeans.astype(float)/n)\n",
    "    ax.scatter(Xb[:, 0], Xb[:, 1], c=colors, s=40, cmap='flare', edgecolor='k');\n",
    "    ax.tick_params(axis='both', which='both', labelsize=20);\n",
    "\n",
    "    ax = axs[0]\n",
    "\n",
    "    for i in np.unique(y_kmeans):\n",
    "        ind = y_kmeans==i\n",
    "        silh = np.sort(silhouette_scores[ind])\n",
    "        size_cluster_i = silh.shape[0]\n",
    "        xupper = xlower + size_cluster_i\n",
    "        color = plt.cm.Accent(float(i)/model.n_clusters)\n",
    "        ax.fill_between(np.arange(xlower, xupper), 0, silh, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ax.axhline(y=0, c='k', lw=2)\n",
    "        ax.text(0.05, 0.95, '%0.0f clusters'%n, transform=ax.transAxes, fontsize=20)\n",
    "        ax.text(0.45, 0.95, 'Mean S. score: %0.2f'%np.mean(silhouette_scores), transform=ax.transAxes, fontsize=20)\n",
    "        xlower = xupper + 10\n",
    "        ax.set_ylabel('Silhouette score', fontsize=16)\n",
    "        ax.set_ylim(-0.15,0.85)\n",
    "        \n",
    "    ax.axhline(y=np.mean(silhouette_scores), color=\"red\", linestyle=\"--\")\n",
    "    ax.tick_params(axis='both', which='both', labelsize=20);\n",
    "    ax.set_xticks([]);\n",
    "#    figname = 'SilhouetteBlobs'+str(n)+'.png'\n",
    "#    plt.savefig(figname, dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density based clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "#Probably missing a source here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.25, min_samples=2).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Compute DBSCAN\n",
    "\n",
    "for i,eps in enumerate([0.2, 0.25, 0.3, 0.35]):\n",
    "    \n",
    "    plt.figure(figsize = (6,6))\n",
    "    \n",
    "    db = DBSCAN(eps=eps, min_samples=2).fit(X)\n",
    "\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "    unique_labels = set(labels)\n",
    "    colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "        # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "\n",
    "        class_member_mask = (labels == k)\n",
    "\n",
    "        xy = X[class_member_mask & core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=10)\n",
    "\n",
    "        xy = X[class_member_mask & ~core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "    plt.title('$\\epsilon$ = %0.2f; estimated number of clusters: %d' % (eps, n_clusters_))\n",
    "    \n",
    "   # plt.savefig('DBSCAN_'+str(i)+'.png', dpi = 300)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial source:\n",
    "    \n",
    "https://scikit-learn.org/stable/auto_examples/cluster/plot_optics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "\n",
    "op = OPTICS(xi=0.05, min_cluster_size=.05).fit(X)\n",
    "\n",
    "labels = op.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "for klass, color in zip(unique_labels[1:], colors[1:]):\n",
    "\n",
    "    Xk = X[op.labels_ == klass]\n",
    "    plt.scatter(Xk[:, 0], Xk[:, 1], 60, np.array([color,]),\\\n",
    "                'o', edgecolors='k',linewidths=1, )#, ls = 'None')\n",
    "    \n",
    "plt.plot(X[op.labels_ == -1, 0], X[op.labels_ == -1, 1], 'k+', ls = 'None')\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the parameter xi will change the estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "\n",
    "op = OPTICS(xi=0.2, min_cluster_size=.05).fit(X)\n",
    "\n",
    "labels = op.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "for klass, color in zip(unique_labels[1:], colors[1:]):\n",
    "\n",
    "    Xk = X[op.labels_ == klass]\n",
    "    plt.scatter(Xk[:, 0], Xk[:, 1], 60, np.array([color,]),\\\n",
    "                'o', edgecolors='k',linewidths=1, )#, ls = 'None')\n",
    "    \n",
    "plt.plot(X[op.labels_ == -1, 0], X[op.labels_ == -1, 1], 'k+', ls = 'None')\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions taken from Vanderplas' book (Data Science w Python)\n",
    "\n",
    "def draw_ellipse(gmm, ax, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    for n in range(gmm.n_components):\n",
    "        if gmm.covariance_type == 'full':\n",
    "            covariances = gmm.covariances_[n]\n",
    "        elif gmm.covariance_type == 'tied':\n",
    "            covariances = gmm.covariances_\n",
    "        elif gmm.covariance_type == 'diag':\n",
    "            covariances = np.diag(gmm.covariances_[n])\n",
    "        elif gmm.covariance_type == 'spherical':\n",
    "            covariances = np.eye(gmm.means_.shape[1]) * gmm.covariances_[n]\n",
    "        v, w = np.linalg.eigh(covariances)\n",
    "        u = w[0] / np.linalg.norm(w[0])\n",
    "        angle = np.arctan2(u[1], u[0])\n",
    "        angle = 180 * angle / np.pi  # convert to degrees\n",
    "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "        \n",
    "        # Draw the Ellipse\n",
    "        for nsig in range(1, 4): #1, 2, and 3 sigma\n",
    "            ell = Ellipse(gmm.means_[n], nsig *v[0], nsig *v[1], angle, **kwargs)\n",
    "            ax.add_patch(ell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from Vanderplas\n",
    " \n",
    "fig, ax = plt.subplots(1, 3, figsize=(14, 4), sharey=True)\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "\n",
    "rng = np.random.RandomState(20)\n",
    "Xe = np.dot(rng.randn(500, 2), rng.randn(2, 2))\n",
    "\n",
    "for i, cov_type in enumerate(['full','diag', 'spherical']):\n",
    "    model = mixture.GaussianMixture(n_components=1, covariance_type=cov_type).fit(X)\n",
    "    ax[i].axis('equal')\n",
    "    ax[i].scatter(Xe[:, 0], Xe[:, 1], edgecolor='k', alpha=0.5)\n",
    "    ax[i].set_title('covariance_type=\"{0}\"'.format(cov_type), size=14, family='monospace')\n",
    "    draw_ellipse(gmm=model, ax=ax[i], alpha=0.1, edgecolor='k', facecolor='#808080')\n",
    "    ax[i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax[i].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    \n",
    "    ax[i].set_xlim(-5, 5)\n",
    "    \n",
    "#plt.savefig('GMM_Covariances.png', dpi = 300)\n",
    "    \n",
    "#plt.show()\n",
    "    #plt.xlim(-5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with a Gaussian Mixture Model predicts probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mixture.GaussianMixture(n_components=3, covariance_type='full',random_state=37) #Good! 0, 1, 2\n",
    "\n",
    "model.fit(Xb)\n",
    "\n",
    "y_GMM = model.predict(Xb)\n",
    "\n",
    "probs = model.predict_proba(Xb)\n",
    "\n",
    "size = 50 * probs.max(axis=1)**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_GMM #(0,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM decision function for a \"full\" covariance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mixture.GaussianMixture(n_components=3, covariance_type='full',random_state=37)\n",
    "\n",
    "model.fit(Xb)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "plt.axis('equal')\n",
    "\n",
    "plot_decision_regions(Xb, yb.astype(int), \n",
    "        clf=model, legend=0, markers = '...', colors = 'lightgray,violet,teal')\n",
    "\n",
    "plt.scatter(X1b[:,0],X1b[:,1], s = size[:len(y1b)], c = 'lightgray',edgecolors='k')\n",
    "\n",
    "plt.scatter(X2b[:,0],X2b[:,1], s = size[len(y1b):len(y1b)+len(y2b)], c = 'violet', edgecolors='k')\n",
    "\n",
    "plt.scatter(X3b[:,0],X3b[:,1],s = size[len(y1b)+len(y2b):], c = 'teal', edgecolors='k')\n",
    "\n",
    "ax.set_title('covariance_type=\"{0}\"'.format('full'), size=14, family='monospace')\n",
    "\n",
    "ax.set_xlim(-2.5, 2.5)\n",
    "ax.set_ylim(-0.5,2.5)\n",
    "\n",
    "#plt.savefig('GMM_blobs_full.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with a spherical covariance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mixture.GaussianMixture(n_components=3, covariance_type='spherical',random_state=37)\n",
    "\n",
    "model.fit(Xb)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "plt.axis('equal')\n",
    "\n",
    "plot_decision_regions(Xb, yb.astype(int), \n",
    "        clf=model, legend=0, markers = '...', colors = 'lightgray,violet,teal')\n",
    "\n",
    "plt.scatter(X1b[:,0],X1b[:,1], s = size[:len(y1b)], c = 'lightgray',edgecolors='k')\n",
    "\n",
    "plt.scatter(X2b[:,0],X2b[:,1], s = size[len(y1b):len(y1b)+len(y2b)], c = 'violet', edgecolors='k')\n",
    "\n",
    "plt.scatter(X3b[:,0],X3b[:,1],s = size[len(y1b)+len(y2b):], c = 'teal', edgecolors='k')\n",
    "\n",
    "ax.set_title('covariance_type=\"{0}\"'.format('spherical'), size=14, family='monospace')\n",
    "\n",
    "ax.set_xlim(-2.5, 2.5)\n",
    "ax.set_ylim(-0.5,2.5)\n",
    "\n",
    "#plt.savefig('GMM_blobs_spherical.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we generate predictions for the smiley face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm4 = mixture.GaussianMixture(n_components=4, covariance_type='full', random_state=0)\n",
    "\n",
    "gmm4.fit(X)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "xy = [point(1,2,1) for _ in range(100)]\n",
    "\n",
    "plot_decision_regions(X, y.astype(int), \n",
    "        clf=gmm4, legend=0, markers = '.', colors = 'lightgray,yellow,teal,violet')\n",
    "\n",
    "plt.scatter(*zip(*xy), s = 30, c = 'lightgray', edgecolors='k')\n",
    "plt.scatter(X1[:,0],X1[:,1], s = 30, c = 'teal',edgecolors='k')\n",
    "plt.scatter(X2[:,0],X2[:,1], s = 30, c = 'violet', edgecolors='k')\n",
    "plt.scatter(X3_stretch.T[:,0]-1.9,X3_stretch.T[:,1],s = 30, c = 'yellow', edgecolors='k')\n",
    "\n",
    "\n",
    "plt.xlim(-0.5,2.5);\n",
    "\n",
    "plt.ylim(0.5,3.5);\n",
    "\n",
    "#plt.savefig('GMMbad.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use the BIC criterion to figure out how many components best fit the smiley face in the GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = np.arange(1, 30)\n",
    "models = [mixture.GaussianMixture(n, covariance_type='full', random_state=0).fit(X)\n",
    "          for n in n_components]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(n_components, [m.bic(X) for m in models], label='BIC')\n",
    "ax.legend(loc='best', fontsize=20)\n",
    "ax.set_xlabel('n_components', fontsize=20);\n",
    "ax.tick_params(axis='both', which='both', labelsize=20);\n",
    "#plt.savefig('GMM_smiley_BIC.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And re-do the plot with the appropriate number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These two functions (note that \"draw_ellipse\" is not the same as before!) are also from Jake Vanderplas' book.\n",
    "\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0.0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height, angle, **kwargs))\n",
    "\n",
    "def plot_gmm(gmm, X, label=True, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = gmm.fit(X).predict(X)\n",
    "    if label:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='Accent', zorder=2, edgecolor='k')\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2, edgecolor='k')\n",
    "    ax.axis('equal')\n",
    "    \n",
    "    w_factor = 0.2 / gmm.weights_.max()\n",
    "    \n",
    "    for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "        draw_ellipse(pos, covar, facecolor='#808080', edgecolor='k', alpha=w * w_factor)\n",
    "        \n",
    "    ax.tick_params(axis='both', which='both', labelsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm10 = mixture.GaussianMixture(n_components=10, covariance_type='full', random_state=0)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = fig.add_subplot(111, aspect='equal')\n",
    "\n",
    "plot_gmm(gmm10, X, label=False, ax=ax)\n",
    "\n",
    "plt.xlim(-0.5,2.5);\n",
    "\n",
    "plt.ylim(0.5,3.5);\n",
    "\n",
    "plt.text(-0.3,0.7,'Original', fontsize = 18)\n",
    "\n",
    "ax.tick_params(axis='both', which='both', labelsize=20);\n",
    "\n",
    "#plt.savefig('Smiley_GMM_10.png', dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we can use our GMM with 10 components as a generative model to generate new samples along the smiley face distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Xnew = gmm10.sample(n_samples=500)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax2 = fig.add_subplot(111, aspect='equal', sharey = ax)\n",
    "\n",
    "ax2.scatter(Xnew[0][:, 0], Xnew[0][:, 1], s = 40, facecolor='r', edgecolor='k', alpha=0.5);\n",
    "\n",
    "ax2.tick_params(axis='both', which='both', labelsize=20);\n",
    "\n",
    "plt.xlim(-0.5,2.5);\n",
    "\n",
    "plt.ylim(0.5,3.5);\n",
    "\n",
    "plt.text(-0.3,0.7,'Generated', fontsize = 18)\n",
    "\n",
    "#plt.savefig('Smiley_GMM_generated.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Check-in\n",
    "    \n",
    "Q: How does the GMM method do at trying to reproduce the smiely face?\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">Answer</summary>\n",
    "<p>\n",
    "Comparing the two grapgs above, we can see where GMM decided to place various distributions. When we use those distributions to generate new points, it can be slightly off and any inaccuracies in the fit become quite apparent.\n",
    "    \n",
    "How do you think any of these cluster methods would fair looking at the generated model? Try it your self!\n",
    "</p>\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}