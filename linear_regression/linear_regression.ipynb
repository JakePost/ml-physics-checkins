{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple notebook to generate linear data with some (non-Gaussian) scatter, and do linear fits with different loss functions.\n",
    "\n",
    "It accompanies Chapter 5 of the book (1 of 5).\n",
    "\n",
    "Author: Viviana Acquaviva, with contributions by Jake Postiglione and Olga Privman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model #New!\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "font = {'size'   : 16}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "matplotlib.rcParams.update({'figure.autolayout': False})\n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We begin by generating some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(16) #set seed for reproducibility purposes\n",
    "\n",
    "x = np.arange(100) \n",
    "\n",
    "yp = 3*x + 3 + 5*(np.random.poisson(3*x+3,100)-(3*x+3)) #generate some data with scatter following Poisson distribution \n",
    "                                                    #with exp value = y from linear model, centered around 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look!\n",
    "\n",
    "plt.scatter(x, yp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here comes the linear regression model ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can fit the model (right now, I will do it using the entire data set just to compare with the analytic solution). When only one predictor is present, I need to reshape it to column form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x.reshape(-1,1),yp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted model has attributes \"coef_\", \"intercept_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept = model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(slope, intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the original and the fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.scatter(x,yp, s = 20, c = 'gray', label = 'Data')\n",
    "plt.plot(x, slope*x + intercept, c ='k', label = 'Ordinary least squares fit')\n",
    "plt.plot(x, 3*x + 3, c = 'r', label = 'True regression line')\n",
    "plt.legend(fontsize = 14)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the analytic predictions for the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions - fill in the analytic formula\n",
    "\n",
    "theta1 = np.sum((x - np.mean(x))*(yp - np.mean(yp)))/np.sum((x - np.mean(x))*(x - np.mean(x)))\n",
    "\n",
    "theta0 = np.mean(yp) - theta1*np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Theta_0, Theta_1:', theta0, theta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also obtain the second one in the variance/covariance notation (note: the small difference is due to 1/n vs 1/(n-1) in the definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample Cov / Sample var:', np.cov(x,yp, bias=True)[0,1]/np.var(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can (and should!) do cross validation and all the nice things we have learned to do for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits = 5 , shuffle = True , random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model, x.reshape(-1,1), yp, cv = cv, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:.3f}'.format(scores['test_score'].mean()), '{:.3f}'.format(scores['test_score'].std()))\n",
    "print('{:.3f}'.format(scores['train_score'].mean()), '{:.3f}'.format(scores['train_score'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: \n",
    "\n",
    "- What are the scores that are being printed out?\n",
    "\n",
    "- How are the scores? \n",
    "\n",
    "- Does it suffer from high variance? High bias?\n",
    "\n",
    "- What would happen to the scores if we increased the scatter (noise)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Scoring in regression problems. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a way to visualize all the available scorers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(sklearn.metrics.SCORERS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do you recognize some of them?\n",
    "\n",
    "Let's see if we can find the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model, x.reshape(-1,1), yp, cv = cv, scoring = 'neg_mean_squared_error', return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('{:.3f}'.format(scores['test_score'].mean()), '{:.3f}'.format(scores['test_score'].std()))\n",
    "print('{:.3f}'.format(scores['train_score'].mean()), '{:.3f}'.format(scores['train_score'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also try MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores = cross_validate(model, x.reshape(-1,1), yp, cv = cv, scoring = 'neg_mean_absolute_error', return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:.3f}'.format(scores['test_score'].mean()), '{:.3f}'.format(scores['test_score'].std()))\n",
    "print('{:.3f}'.format(scores['train_score'].mean()), '{:.3f}'.format(scores['train_score'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting the residuals, we can see that they are independent of x (the assumptions of the probabilistic linear model are not satisfied). But that doesn't mean we can't create a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, slope*x + intercept - yp, color = 'b', label = 'Residuals')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might like to implement a scorer where we care about percentage error instead. Here is how to do a custom scorer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Check-in\n",
    "    \n",
    "How would you implement a scorer? Please fill in the code.\n",
    "\n",
    "```python\n",
    "def mape(...,...): #Mean Absolute Percentage Error\n",
    "    return ....\n",
    "\n",
    "mape_scorer = make_scorer(mape, greater_is_better = False)\n",
    "```\n",
    "\n",
    "</br>\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">Click here for the answer!</summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "def mape(true,pred): #Mean Absolute Percentage Error\n",
    "    return np.mean(np.abs(true-pred)/(true))\n",
    "\n",
    "mape_scorer = make_scorer(mape, greater_is_better = False)\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try it with Modified Mean Absolute Percentage Error, instead, to avoid zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(true,pred): #Modified Mean Absolute Percentage Error\n",
    "    return np.mean(np.abs(true-pred)/(0.5*(true+pred)))\n",
    "\n",
    "mape_scorer = make_scorer(mape, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model, x.reshape(-1,1), yp, cv = cv, scoring = mape_scorer, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:.3f}'.format(scores['test_score'].mean()), '{:.3f}'.format(scores['test_score'].std()))\n",
    "print('{:.3f}'.format(scores['train_score'].mean()), '{:.3f}'.format(scores['train_score'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: as we already discussed, so far we have not changed the loss function (MSE), or the coefficients of the model. We have only looked at different evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'green'> Question 1: would the best fit line change if we optimize a different loss function? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'green'> Question 2: How can we implement that without an analytic solution? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example using the Mean Square Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = np.linspace(-5,5,200)\n",
    "theta1 = np.linspace(-5,5,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.empty((200,200))\n",
    "\n",
    "for i,t0 in enumerate(theta0):\n",
    "    for j,t1 in enumerate(theta1):\n",
    "        mse[i,j] = np.sum((t0 + t1*x - yp)**2)/len(yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the indices of the 2D array, I need to unravel it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(mse.argmin(), mse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now find the minimum MSE (not very informative, TBH) and the best fit coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse[25,160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0[25], theta1[160]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: How do they compare to the ones found by the Linear Model / analytic ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be interesting to see what happens to the parameters if we use a different loss function (MAE, MAPE, Huber loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, because these data are so regular, it's kind of boring, so before trying the different losses let's inject some outliers in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens when we add outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12) #set \n",
    "out = np.random.choice(100,15) #select 15 outliers indexes\n",
    "yp_wo = np.copy(yp)\n",
    "np.random.seed(12) #set again\n",
    "yp_wo[out] = yp_wo[out] + 5*np.random.rand(15)*yp[out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,yp_wo, label = 'Data + outliers')\n",
    "plt.scatter(x,yp, label = 'Original data')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the effect for the MSE loss right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x.reshape(-1,1),yp_wo)\n",
    "\n",
    "slope, intercept = model.coef_, model.intercept_\n",
    "\n",
    "print(slope, intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Check-in\n",
    "    \n",
    "What can we expect when we increase the number of outliers to 30?\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">Click here for the answer!</summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "The new values are visibly skewed by the outliers.\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>\n",
    "\n",
    "</br>\n",
    "\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "What are the new values for the slope and intercept? \n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">Click here for the answer!</summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "[4.39426943] 5.633663366336549\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "1. Calculate the best fitting coefficients (e.g. using a grid, like the one we made in the previous example) for the MSE, MAE and modified MAPE, and Huber loss.\n",
    "\n",
    "2. Plot the data and the four best fits.\n",
    "\n",
    "3. Explain the results by commenting on the differences.\n",
    "\n",
    "Note: the Huber loss is a hybrid between MSE and MAE (behaves like MAE when the error is larger than a certain amount, often called delta, so it's less sensitive to outliers). One possibility is to use the std of the y values to set delta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://www.astroml.org/book_figures/chapter8/fig_huber_loss.html\n",
    "\n",
    "# Define the log-likelihood via the Huber loss function\n",
    "def huber_loss(m, b, x, y, dy, c=2):\n",
    "    y_fit = m * x + b\n",
    "    t = abs((y - y_fit) / dy)\n",
    "    flag = t > c\n",
    "    return np.sum((~flag) * (0.5 * t ** 2) - (flag) * c * (0.5 * c - t), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0 = np.linspace(-5,5,200)\n",
    "b1 = np.linspace(-5,5,200)\n",
    "\n",
    "losses = ['MSE', 'MAE', 'MAPE', 'Huber']\n",
    "\n",
    "mse = np.empty((200,200))\n",
    "mae = np.empty((200,200))\n",
    "mape = np.empty((200,200))\n",
    "huber = np.empty((200,200))\n",
    "\n",
    "c = 209 #Huber\n",
    "\n",
    "coeff = {}\n",
    "\n",
    "for i,beta0 in enumerate(b0):\n",
    "    for j,beta1 in enumerate(b1):\n",
    "        \n",
    "        #MSE\n",
    "        mse[i,j] = np.sum((beta0 + beta1*x - yp_wo)**2)/len(yp_wo)\n",
    "        \n",
    "        #MAE\n",
    "        mae[i,j] = np.sum(np.abs(beta0 + beta1*x - yp_wo))/len(yp_wo)\n",
    "            \n",
    "        #MAPE\n",
    "        mape[i,j] = np.sum(np.abs(beta0 + beta1*x - yp_wo)/yp_wo)/len(yp_wo)\n",
    "        \n",
    "        #Huber\n",
    "        t = np.abs(beta0 + beta1*x - yp_wo)\n",
    "        flag = (t > c)\n",
    "        huber[i,j] = np.sum((~flag) * (0.5 * t ** 2) - (flag) * c * (0.5 * c - t))/len(yp_wo)\n",
    "\n",
    "for i,loss in enumerate([mse, mae, mape, huber]):\n",
    "        \n",
    "    ind = np.unravel_index(loss.argmin(), loss.shape)\n",
    "    \n",
    "    coeff[losses[i]] = b0[ind[0]], b1[ind[1]]\n",
    "\n",
    "    print('Intercept, slope for loss:', losses[i], b0[ind[0]], b1[ind[1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
