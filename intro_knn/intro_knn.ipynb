{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a simple notebook to build and visualize the kNN algorithm.\n",
    "\n",
    "It accompanies Chapter 2 of the book.\n",
    "\n",
    "Author: Viviana Acquaviva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split # we don't use it here, but it's a useful function!\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # how methods are imported \n",
    "\n",
    "from sklearn import metrics # this will give us access to evaluation metrics\n",
    "\n",
    "from sklearn import neighbors # here comes the method of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet = pd.read_csv('../data/HPLearningSet.csv')\n",
    "\n",
    "LearningSet = LearningSet.drop(LearningSet.columns[0], axis=1) #We want to drop the first column of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By now we know data frames\n",
    "\n",
    "LearningSet #Visualizes the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's pick the same train/test set we had in the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet =  LearningSet.iloc[:13,:] #.iloc is used to slice data frames using positional indexes\n",
    "\n",
    "TestSet = LearningSet.iloc[13:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We split the train and test sets in features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = TrainSet.drop(['P_NAME','P_HABITABLE'],axis=1) #This contains stellar mass, period, and distance\n",
    "\n",
    "Xtest = TestSet.drop(['P_NAME','P_HABITABLE'],axis=1)  #This contains stellar mass, period, and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = TrainSet.P_HABITABLE #This contains the ground truth label, or output\n",
    "\n",
    "ytest = TestSet.P_HABITABLE #This contains the ground truth  label, or output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are now ready to deploy the kNN (k Nearest Neighbor) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a simple algorithm based on the idea of distance: we look for the k (an integer) objects that are closest to the one we would like to classify, and take the majority vote among the k classes of the k neighbors.\n",
    "\n",
    "If you are wondering: what is even there to fit?\n",
    "\n",
    "I had the same question, and found some solace in [this post](https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Check-In: \n",
    "\n",
    "How would you code increasing neighbors to 5? Test your code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enter code in this cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Click here for the answer!</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For visualization purposes, let's use only the first two features to build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model by fitting training set; predict labels for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can chain the fit/predict process like this, or use the fit_predict method\n",
    "\n",
    "model.fit(Xtrain.iloc[:,:2],ytrain) #this fits the model, which can then be used to predict stuff\n",
    "\n",
    "ytestpred = model.predict(Xtest.iloc[:,:2]) #this uses the fitted model to predict the labels from the 5 objects in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytestpred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Check-in\n",
    "   \n",
    "Can you predict the labels for the training set? What is the correct code? Test your code in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enter code in this cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Click here for the answer!</b></summary>\n",
    "<p>\n",
    "\n",
    "```\n",
    "ytrainpred = model.predict(Xtrain.iloc[:,:2])\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytestpred, ytest.values #compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate accuracy on the train set and on the test set (train score and test score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Check-In:\n",
    "\n",
    "Calculate the accuracy on the train set and on the test set (train score and test score)\n",
    "\n",
    "<details><summary><b>Click here for the answer!</b></summary>\n",
    "<p>\n",
    "   \n",
    "```markdown\n",
    "~ 0.692\n",
    "    \n",
    "0.8\n",
    "```\n",
    "   \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(ytrain, model.predict(Xtrain.iloc[:,:2]))) #This compares the true labels for the train set with the predicted labels fro the train set\n",
    "\n",
    "print(metrics.accuracy_score(ytest, model.predict(Xtest.iloc[:,:2]))) #This compares the true labels for the test set with the predicted labels fro the test set\n",
    "                                                                      #(same that we did above)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Check-in\n",
    "\n",
    "Great! Now what would the train and test accuracy be if we increased neighbors to 5?\n",
    "\n",
    "<details><summary><b>Click here for the answer!</b></summary>\n",
    "<p>\n",
    "   \n",
    "```\n",
    "~ 0.615\n",
    "0.8\n",
    "```\n",
    "   \n",
    "</p>\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After fitting and predicting, we can access the k neighbors for each element in the test set like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.kneighbors(Xtest.iloc[:,:2]) #the first element gives the distances, the second the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now visualize our results, similarly to what we did for the DT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the largest distances as the radius of the circles - every point inside the circle is a neighbor!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(TestSet)): # cycle through elements of the test set\n",
    "    \n",
    "    print(model.kneighbors(Xtest.iloc[:,:2])[0][i,2]) # this prints out the third element of the distances vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "\n",
    "a = plt.scatter(TrainSet['S_MASS'], TrainSet['P_PERIOD'], marker=\"$\\u2606$\", facecolor = 'none',\\\n",
    "            c = TrainSet['P_HABITABLE'], s = 100, label = 'Train', cmap=cmap)\n",
    "\n",
    "a = plt.scatter(TestSet['S_MASS'], TestSet['P_PERIOD'], marker=\"$\\u25EF$\",facecolors = 'none',\\\n",
    "            c = TestSet['P_HABITABLE'], s = 100, label = 'Test', cmap=cmap)\n",
    "\n",
    "for i in range(len(TestSet)): #plot neighbors\n",
    "\n",
    "    circle1=plt.Circle((TestSet['S_MASS'].iloc[i],TestSet['P_PERIOD'].iloc[i]),model.kneighbors(Xtest.iloc[:,:2])[0][i,2],\\\n",
    "                       lw = 0.7, edgecolor='k',facecolor='none')\n",
    "    plt.gca().add_artist(circle1)\n",
    "    \n",
    "plt.gca().set_aspect(1)\n",
    "\n",
    "bluepatch = mpatches.Patch(color='#20B2AA', label='Not Habitable')\n",
    "magentapatch = mpatches.Patch(color='#FF00FF', label='Habitable')\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "ax = plt.gca()\n",
    "leg = ax.get_legend()\n",
    "leg.legendHandles[0].set_color('k')\n",
    "leg.legendHandles[0].set_facecolor('none')\n",
    "leg.legendHandles[1].set_color('k')\n",
    "leg.legendHandles[1].set_facecolor('none')\n",
    "\n",
    "\n",
    "plt.legend(handles=[leg.legendHandles[0],leg.legendHandles[1], magentapatch, bluepatch],\\\n",
    "           loc = 'upper left', fontsize = 14)\n",
    "\n",
    "plt.xlim(-130,70)\n",
    "plt.ylim(0,140)\n",
    "plt.xlabel('Mass of Parent Star (Solar Mass Units)')\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "#plt.savefig('HabPlanetsKNN2features.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do you notice any issue here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If one dimension has a much bigger range than others, it will dominate the decision process. This issue can be solved by <b>scaling</b>. Scaling is a very important pre-processing step for most ML algorithms.\n",
    "\n",
    "See some examples of different scaling algorithms [here](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html).\n",
    "\n",
    "We will go with RobustScaler, which is more resistant to outliers than the standard version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(Xtrain) # important: we only scale the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledXTrain = scaler.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledXTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledXtest = scaler.transform(Xtest) # note that these are now numpy arrays, not data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform #This unscales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(scaledXTrain[:,:2],ytrain).predict(scaledXtest[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.kneighbors(scaledXtest[:,:2]) #The distances of neighbors for test set objects look more balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))#, aspect_ratio = 'equal')\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "plt.scatter(scaledXTrain[:,0], scaledXTrain[:,1], marker = '*',\\\n",
    "            c = ytrain, s = 100, label = 'Train', cmap=cmap) #, \n",
    "\n",
    "plt.scatter(scaledXtest[:,0], scaledXtest[:,1], marker = 'o',\\\n",
    "            c = ytest, s = 100, label = 'Test', cmap=cmap) #label = ,\n",
    "\n",
    "for i in range(len(TestSet)):\n",
    "\n",
    "    circle1=plt.Circle((scaledXtest[i,0],scaledXtest[i,1]),model.kneighbors(scaledXtest[:,:2])[0][i,2],\\\n",
    "                       edgecolor='k',facecolor='none', lw = 0.7)\n",
    "    plt.gca().add_artist(circle1)\n",
    "\n",
    "plt.gca().set_aspect(1)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax = plt.gca()\n",
    "leg = ax.get_legend()\n",
    "leg.legendHandles[0].set_color('k')\n",
    "#leg.legendHandles[0].set_facecolor('none')\n",
    "leg.legendHandles[1].set_color('k')\n",
    "#leg.legendHandles[1].set_facecolor('none')\n",
    "\n",
    "\n",
    "plt.legend(handles=[leg.legendHandles[0], leg.legendHandles[1]], loc = 'upper right', fontsize = 14)\n",
    "\n",
    "plt.xlabel('Mass of Parent Star (Earth Mass Units)')\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "\n",
    "plt.xlim(-2.5,2.5)\n",
    "plt.ylim(-1.,2.5);\n",
    "\n",
    "#plt.savefig('HabPlanetsKNNscaled.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: for the purpose of application (not visualization), we should use all three features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final remarks:\n",
    "    \n",
    "kNN needs scaling! Does DT have the same issue?\n",
    "\n",
    "Any thoughts on strengths/weaknesses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}